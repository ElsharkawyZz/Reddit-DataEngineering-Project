[2024-02-14T00:00:05.259+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [queued]>
[2024-02-14T00:00:05.276+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [queued]>
[2024-02-14T00:00:05.278+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T00:00:05.310+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-02-13 00:00:00+00:00
[2024-02-14T00:00:05.323+0000] {standard_task_runner.py:60} INFO - Started process 201 to run task
[2024-02-14T00:00:05.329+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'scheduled__2024-02-13T00:00:00+00:00', '--job-id', '59', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpij7yp6hp']
[2024-02-14T00:00:05.334+0000] {standard_task_runner.py:88} INFO - Job 59: Subtask reddit_extraction
[2024-02-14T00:00:05.427+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [running]> on host edfa37962e49
[2024-02-14T00:00:05.593+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ahmed Elsharkawy' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-13T00:00:00+00:00'
[2024-02-14T00:00:05.971+0000] {logging_mixin.py:188} INFO - connected to reddit!
[2024-02-14T00:00:07.337+0000] {logging_mixin.py:188} INFO - {'id': '1aphlml', 'title': 'Using pandas in a data-intensive application - what the best, RAM-efficient, alternative?', 'score': 38, 'num_comments': 32, 'author': Redditor(name='NFeruch'), 'created_utc': 1707789155.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aphlml/using_pandas_in_a_dataintensive_application_what/', 'over_18': False, 'edited': 1707789616.0, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.339+0000] {logging_mixin.py:188} INFO - {'id': '1apolbz', 'title': 'The only two books you need to read about CI/CD and Data', 'score': 35, 'num_comments': 23, 'author': Redditor(name='OnlyFish7104'), 'created_utc': 1707812439.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/', 'over_18': False, 'edited': 1707812720.0, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.340+0000] {logging_mixin.py:188} INFO - {'id': '1apkimj', 'title': "What are instances where data storage, ETL, analytics, etc don't make sense on the cloud?", 'score': 28, 'num_comments': 20, 'author': Redditor(name='Reddit_Account_C-137'), 'created_utc': 1707797667.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.341+0000] {logging_mixin.py:188} INFO - {'id': '1apqjnd', 'title': 'Pick 30% paybump for a small company or work in a big bank?', 'score': 26, 'num_comments': 26, 'author': Redditor(name='Leopatto'), 'created_utc': 1707820828.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.342+0000] {logging_mixin.py:188} INFO - {'id': '1apz616', 'title': 'Passed AWS Data Engineer - Associate !', 'score': 20, 'num_comments': 13, 'author': Redditor(name='dev_lvl80'), 'created_utc': 1707845473.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/', 'over_18': False, 'edited': 1707847512.0, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.343+0000] {logging_mixin.py:188} INFO - {'id': '1apkw7y', 'title': 'Resources for data modeling and building a data architecture for event data', 'score': 19, 'num_comments': 16, 'author': Redditor(name='Several_Percentage_5'), 'created_utc': 1707798861.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/', 'over_18': False, 'edited': 1707822875.0, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.344+0000] {logging_mixin.py:188} INFO - {'id': '1apzymj', 'title': 'How would I go about creating a small-scale data warehouse for a small business team?', 'score': 14, 'num_comments': 14, 'author': Redditor(name='AstralSerenity'), 'created_utc': 1707847340.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/', 'over_18': False, 'edited': 1707847774.0, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.345+0000] {logging_mixin.py:188} INFO - {'id': '1apip8g', 'title': 'Whats the proper way to apply for internal job', 'score': 8, 'num_comments': 10, 'author': Redditor(name='liskeeksil'), 'created_utc': 1707792313.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apip8g/whats_the_proper_way_to_apply_for_internal_job/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.346+0000] {logging_mixin.py:188} INFO - {'id': '1apwl21', 'title': 'Dagster Feedback?', 'score': 7, 'num_comments': 11, 'author': Redditor(name='minormisgnomer'), 'created_utc': 1707839274.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.347+0000] {logging_mixin.py:188} INFO - {'id': '1apv4t0', 'title': 'Connectomics Data Challenge', 'score': 7, 'num_comments': 0, 'author': Redditor(name='amyleerobinson'), 'created_utc': 1707835553.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.348+0000] {logging_mixin.py:188} INFO - {'id': '1aq0u4f', 'title': 'Job Market for Foreigners', 'score': 5, 'num_comments': 9, 'author': Redditor(name='luishacm'), 'created_utc': 1707849432.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.349+0000] {logging_mixin.py:188} INFO - {'id': '1appuju', 'title': 'Are GenAI& PandasAi safe to use for confidential data ??', 'score': 5, 'num_comments': 5, 'author': Redditor(name='TylerTheBat'), 'created_utc': 1707817934.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.350+0000] {logging_mixin.py:188} INFO - {'id': '1aq01f4', 'title': 'one-to-one relationships in star schema', 'score': 4, 'num_comments': 6, 'author': Redditor(name='pdxtechnologist'), 'created_utc': 1707847529.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.351+0000] {logging_mixin.py:188} INFO - {'id': '1aq00v5', 'title': 'What is the difference between a data mart and a regular data model?', 'score': 5, 'num_comments': 1, 'author': Redditor(name='TaleLegal9085'), 'created_utc': 1707847492.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.352+0000] {logging_mixin.py:188} INFO - {'id': '1apktdn', 'title': 'Can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage?', 'score': 5, 'num_comments': 7, 'author': Redditor(name='JK_1975'), 'created_utc': 1707798612.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.353+0000] {logging_mixin.py:188} INFO - {'id': '1apxt0o', 'title': 'Data teams building in public repositories', 'score': 3, 'num_comments': 0, 'author': Redditor(name='Wingsofpeace7'), 'created_utc': 1707842230.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.354+0000] {logging_mixin.py:188} INFO - {'id': '1aptdwv', 'title': 'Teradata Vantageâ„¢ destination now available on Airbyte Cloud', 'score': 3, 'num_comments': 0, 'author': Redditor(name='JanethL'), 'created_utc': 1707830668.0, 'url': 'https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.356+0000] {logging_mixin.py:188} INFO - {'id': '1aps1ts', 'title': 'Using Power BI as frontend and Databricks as compute engine for data products', 'score': 3, 'num_comments': 8, 'author': Redditor(name='No_Lawfulness_6252'), 'created_utc': 1707826507.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.357+0000] {logging_mixin.py:188} INFO - {'id': '1appi2g', 'title': 'Partitioning Limit in Kafka', 'score': 3, 'num_comments': 2, 'author': Redditor(name='Plus-Author9252'), 'created_utc': 1707816417.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.358+0000] {logging_mixin.py:188} INFO - {'id': '1apv2d7', 'title': 'How to establish an OLE DB Destination in SSIS?', 'score': 2, 'num_comments': 0, 'author': Redditor(name='imperialka'), 'created_utc': 1707835372.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.359+0000] {logging_mixin.py:188} INFO - {'id': '1apslj8', 'title': '9 Ways to Sell Data Services to Non-Data-Savvy Clients', 'score': 2, 'num_comments': 0, 'author': Redditor(name='sbalnojan'), 'created_utc': 1707828296.0, 'url': 'https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.360+0000] {logging_mixin.py:188} INFO - {'id': '1aps4cd', 'title': 'Vertex ai and code', 'score': 2, 'num_comments': 0, 'author': Redditor(name='Total_Definition_401'), 'created_utc': 1707826748.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.360+0000] {logging_mixin.py:188} INFO - {'id': '1aposzs', 'title': 'Distributed time-series processing?', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Sea_Pipe9828'), 'created_utc': 1707813349.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.362+0000] {logging_mixin.py:188} INFO - {'id': '1aphgks', 'title': 'Data quality tool for extracts (txt/delimited, .csv etcâ€¦)', 'score': 2, 'num_comments': 2, 'author': Redditor(name='mg_1987'), 'created_utc': 1707788747.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aphgks/data_quality_tool_for_extracts_txtdelimited_csv/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.362+0000] {logging_mixin.py:188} INFO - {'id': '1aq76lv', 'title': 'VectorBT for Quantitative Analysis in Python', 'score': 1, 'num_comments': 0, 'author': Redditor(name='fancypigollo'), 'created_utc': 1707864873.0, 'url': 'https://youtu.be/t93aVVAP19E?si=PjXIOOinxDI-KzxU', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.363+0000] {logging_mixin.py:188} INFO - {'id': '1aq6kpm', 'title': 'DBT generic schema tests questions', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Interesting-Goose82'), 'created_utc': 1707863377.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.365+0000] {logging_mixin.py:188} INFO - {'id': '1aq6dbj', 'title': 'Have you tried these tools? If not, why?', 'score': 6, 'num_comments': 12, 'author': Redditor(name='AMDataLake'), 'created_utc': 1707862868.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.366+0000] {logging_mixin.py:188} INFO - {'id': '1aq0dor', 'title': 'How to open files from Databricks Workspace in Notebooks?', 'score': 0, 'num_comments': 4, 'author': Redditor(name='Mysterious_Two_810'), 'created_utc': 1707848329.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq0dor/how_to_open_files_from_databricks_workspace_in/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.367+0000] {logging_mixin.py:188} INFO - {'id': '1aq07hq', 'title': 'Compiling a List of Essential Terms in Data Engineering', 'score': 1, 'num_comments': 3, 'author': Redditor(name='Data-Queen-Mayra'), 'created_utc': 1707847929.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq07hq/compiling_a_list_of_essential_terms_in_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.367+0000] {logging_mixin.py:188} INFO - {'id': '1apywog', 'title': 'What are you using to extract Google Analytics (GA4) and Google Ads data?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='giuliosmall'), 'created_utc': 1707844850.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apywog/what_are_you_using_to_extract_google_analytics/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.368+0000] {logging_mixin.py:188} INFO - {'id': '1apy1bd', 'title': 'Free Badges.', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Wide_Philosopher9589'), 'created_utc': 1707842785.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apy1bd/free_badges/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.369+0000] {logging_mixin.py:188} INFO - {'id': '1apv42h', 'title': 'Using dbt with two different snowflake accounts? Looking for input.', 'score': 1, 'num_comments': 4, 'author': Redditor(name='MasterKluch'), 'created_utc': 1707835500.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv42h/using_dbt_with_two_different_snowflake_accounts/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.370+0000] {logging_mixin.py:188} INFO - {'id': '1aptwme', 'title': 'folks in mid-sized startups, need help in validating my idea ðŸ™Œ', 'score': 1, 'num_comments': 0, 'author': Redditor(name='thehungryindian'), 'created_utc': 1707832153.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aptwme/folks_in_midsized_startups_need_help_in/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.371+0000] {logging_mixin.py:188} INFO - {'id': '1aptmob', 'title': 'My ETL performs full load every day but I want to extract true I/U/Ds out of it.', 'score': 1, 'num_comments': 0, 'author': Redditor(name='gkmanu9'), 'created_utc': 1707831389.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aptmob/my_etl_performs_full_load_every_day_but_i_want_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.372+0000] {logging_mixin.py:188} INFO - {'id': '1apry9n', 'title': 'CosmosDb (mongo) to Postgres', 'score': 1, 'num_comments': 2, 'author': Redditor(name='quincycs'), 'created_utc': 1707826156.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apry9n/cosmosdb_mongo_to_***/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.374+0000] {logging_mixin.py:188} INFO - {'id': '1apqda9', 'title': 'Why not send processed data from speed layer to batch layer in Lambda?', 'score': 1, 'num_comments': 3, 'author': Redditor(name='No_Dentist7884'), 'created_utc': 1707820110.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apqda9/why_not_send_processed_data_from_speed_layer_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.375+0000] {logging_mixin.py:188} INFO - {'id': '1apq39i', 'title': 'Best Practices for Updating Raw Data in Data Science Projects?', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Free-Orange2290'), 'created_utc': 1707818971.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apq39i/best_practices_for_updating_raw_data_in_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.376+0000] {logging_mixin.py:188} INFO - {'id': '1appyni', 'title': 'Data Collection / Asyncio / Brightdata Proxies', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Saa3dLfachil'), 'created_utc': 1707818442.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appyni/data_collection_asyncio_brightdata_proxies/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.377+0000] {logging_mixin.py:188} INFO - {'id': '1apl1l7', 'title': 'Do you use a service mesh, manage IPs yourself?', 'score': 1, 'num_comments': 1, 'author': Redditor(name='DuckDatum'), 'created_utc': 1707799331.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apl1l7/do_you_use_a_service_mesh_manage_ips_yourself/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.377+0000] {logging_mixin.py:188} INFO - {'id': '1apks31', 'title': 'Who are using data virtualization tools and whatâ€™s the best so far?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='ZetarisCommunityLead'), 'created_utc': 1707798497.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apks31/who_are_using_data_virtualization_tools_and_whats/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T00:00:07.440+0000] {python.py:201} INFO - Done. Returned value was: /opt/airflow/data/output/reddit_20240214.csv
[2024-02-14T00:00:07.482+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20240213T000000, start_date=20240214T000005, end_date=20240214T000007
[2024-02-14T00:00:07.554+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T00:00:07.600+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-14T15:17:50.427+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [queued]>
[2024-02-14T15:17:50.467+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [queued]>
[2024-02-14T15:17:50.474+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-14T15:17:50.528+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-02-13 00:00:00+00:00
[2024-02-14T15:17:50.562+0000] {standard_task_runner.py:60} INFO - Started process 57 to run task
[2024-02-14T15:17:50.595+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'scheduled__2024-02-13T00:00:00+00:00', '--job-id', '66', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpeipq6bs5']
[2024-02-14T15:17:50.616+0000] {standard_task_runner.py:88} INFO - Job 66: Subtask reddit_extraction
[2024-02-14T15:17:50.902+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-02-13T00:00:00+00:00 [running]> on host 5e6bd48f135b
[2024-02-14T15:17:51.282+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ahmed Elsharkawy' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-02-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-13T00:00:00+00:00'
[2024-02-14T15:17:52.032+0000] {logging_mixin.py:188} INFO - connected to reddit!
[2024-02-14T15:17:53.829+0000] {logging_mixin.py:188} INFO - {'id': '1apz616', 'title': 'Passed AWS Data Engineer - Associate !', 'score': 48, 'num_comments': 14, 'author': Redditor(name='dev_lvl80'), 'created_utc': 1707845473.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/', 'over_18': False, 'edited': 1707847512.0, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.831+0000] {logging_mixin.py:188} INFO - {'id': '1aqcvov', 'title': 'DBT Column Level Lineage only for DBT Cloud customers', 'score': 28, 'num_comments': 6, 'author': Redditor(name='Culpgrant21'), 'created_utc': 1707880629.0, 'url': 'https://www.getdbt.com/blog/proactively-improve-your-dbt-projects-with-new-dbt-explorer-features/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.833+0000] {logging_mixin.py:188} INFO - {'id': '1apzymj', 'title': 'How would I go about creating a small-scale data warehouse for a small business team?', 'score': 23, 'num_comments': 22, 'author': Redditor(name='AstralSerenity'), 'created_utc': 1707847340.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/', 'over_18': False, 'edited': 1707847774.0, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.838+0000] {logging_mixin.py:188} INFO - {'id': '1aq6dbj', 'title': 'Have you tried these tools? If not, why?', 'score': 20, 'num_comments': 40, 'author': Redditor(name='AMDataLake'), 'created_utc': 1707862868.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq6dbj/have_you_tried_these_tools_if_not_why/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.843+0000] {logging_mixin.py:188} INFO - {'id': '1aqhsg8', 'title': 'Interview question', 'score': 16, 'num_comments': 10, 'author': Redditor(name='Fantastic-Bell5386'), 'created_utc': 1707897837.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqhsg8/interview_question/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.849+0000] {logging_mixin.py:188} INFO - {'id': '1aq7xh9', 'title': "Who's Using Data Catalogs? Need your insights !", 'score': 12, 'num_comments': 6, 'author': Redditor(name='SignificanceNo136'), 'created_utc': 1707866755.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq7xh9/whos_using_data_catalogs_need_your_insights/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.855+0000] {logging_mixin.py:188} INFO - {'id': '1apwl21', 'title': 'Dagster Feedback?', 'score': 14, 'num_comments': 11, 'author': Redditor(name='minormisgnomer'), 'created_utc': 1707839274.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.864+0000] {logging_mixin.py:188} INFO - {'id': '1aqmnx0', 'title': "My company just let me open source our orchestration tool 'Houston', an API based alternative to Airflow/Google Cloud Composer that we've been using internally for the last 4 years! It's great for low-cost, high-speed data pipelines", 'score': 10, 'num_comments': 1, 'author': Redditor(name='flo0d'), 'created_utc': 1707916658.0, 'url': 'https://github.com/datasparq-ai/houston', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.882+0000] {logging_mixin.py:188} INFO - {'id': '1aq0u4f', 'title': 'Job Market for Foreigners', 'score': 7, 'num_comments': 10, 'author': Redditor(name='luishacm'), 'created_utc': 1707849432.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.906+0000] {logging_mixin.py:188} INFO - {'id': '1aqk7rs', 'title': 'New DuckDB Array Type used for Vector databasing on top of Postgres', 'score': 7, 'num_comments': 0, 'author': Redditor(name='squareape'), 'created_utc': 1707908193.0, 'url': 'https://luukvandervelden.medium.com/vector-databasing-with-duckdb-on-top-of-pgvector-ec182f815a16?source=friends_link&sk=041d8e614e2b4ada23af79205661e0d3', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.914+0000] {logging_mixin.py:188} INFO - {'id': '1aq8qdc', 'title': 'Seeking recommendation for tools that will work for a specific architecture', 'score': 5, 'num_comments': 0, 'author': Redditor(name='endotronic'), 'created_utc': 1707868806.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq8qdc/seeking_recommendation_for_tools_that_will_work/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.920+0000] {logging_mixin.py:188} INFO - {'id': '1aq01f4', 'title': 'one-to-one relationships in star schema', 'score': 6, 'num_comments': 7, 'author': Redditor(name='pdxtechnologist'), 'created_utc': 1707847529.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.935+0000] {logging_mixin.py:188} INFO - {'id': '1aq00v5', 'title': 'What is the difference between a data mart and a regular data model?', 'score': 5, 'num_comments': 3, 'author': Redditor(name='TaleLegal9085'), 'created_utc': 1707847492.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.938+0000] {logging_mixin.py:188} INFO - {'id': '1apxt0o', 'title': 'Data teams building in public repositories', 'score': 4, 'num_comments': 2, 'author': Redditor(name='Wingsofpeace7'), 'created_utc': 1707842230.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.940+0000] {logging_mixin.py:188} INFO - {'id': '1aqjqpf', 'title': 'Which certification should I get ?', 'score': 4, 'num_comments': 11, 'author': Redditor(name='tn_receptionist_1520'), 'created_utc': 1707906287.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqjqpf/which_certification_should_i_get/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.944+0000] {logging_mixin.py:188} INFO - {'id': '1aqee7l', 'title': 'Dataframe overwritten using data from another notebook - Azure Databricks', 'score': 5, 'num_comments': 13, 'author': Redditor(name='dilkushpatel'), 'created_utc': 1707885360.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqee7l/dataframe_overwritten_using_data_from_another/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.947+0000] {logging_mixin.py:188} INFO - {'id': '1aq6kpm', 'title': 'DBT generic schema tests questions', 'score': 4, 'num_comments': 7, 'author': Redditor(name='Interesting-Goose82'), 'created_utc': 1707863377.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq6kpm/dbt_generic_schema_tests_questions/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.949+0000] {logging_mixin.py:188} INFO - {'id': '1aqoezb', 'title': 'Announcing DuckDB 0.10.0', 'score': 4, 'num_comments': 0, 'author': Redditor(name='commandlineluser'), 'created_utc': 1707921601.0, 'url': 'https://duckdb.org/2024/02/13/announcing-duckdb-0100.html', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.953+0000] {logging_mixin.py:188} INFO - {'id': '1aqfd8q', 'title': 'Soda core for Delta lake', 'score': 3, 'num_comments': 1, 'author': Redditor(name='Islamic_justice'), 'created_utc': 1707888601.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqfd8q/soda_core_for_delta_lake/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.962+0000] {logging_mixin.py:188} INFO - {'id': '1apywog', 'title': 'What are you using to extract Google Analytics (GA4) and Google Ads data?', 'score': 3, 'num_comments': 0, 'author': Redditor(name='giuliosmall'), 'created_utc': 1707844850.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apywog/what_are_you_using_to_extract_google_analytics/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.967+0000] {logging_mixin.py:188} INFO - {'id': '1aqogdc', 'title': 'How much does title matter?', 'score': 2, 'num_comments': 2, 'author': Redditor(name='bcw28511'), 'created_utc': 1707921699.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqogdc/how_much_does_title_matter/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.972+0000] {logging_mixin.py:188} INFO - {'id': '1aqkvme', 'title': 'Converting MySQL DB to SQL Server', 'score': 2, 'num_comments': 0, 'author': Redditor(name='das3012'), 'created_utc': 1707910686.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqkvme/converting_mysql_db_to_sql_server/', 'over_18': False, 'edited': 1707918740.0, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.978+0000] {logging_mixin.py:188} INFO - {'id': '1aqhrti', 'title': 'Embedding Tableau dashboards in a web app', 'score': 2, 'num_comments': 0, 'author': Redditor(name='OnlyFish7104'), 'created_utc': 1707897765.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqhrti/embedding_tableau_dashboards_in_a_web_app/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.986+0000] {logging_mixin.py:188} INFO - {'id': '1aqbftj', 'title': 'Completed IBM Data Engineering Professional Certificate. Now what?', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Cheetohcrank'), 'created_utc': 1707876359.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqbftj/completed_ibm_data_engineering_professional/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.988+0000] {logging_mixin.py:188} INFO - {'id': '1aqavuu', 'title': 'Best way to import parquet files into multiple Redshift tables based on source directory name using AWS Glue?', 'score': 2, 'num_comments': 3, 'author': Redditor(name='crampedTurtle'), 'created_utc': 1707874766.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqavuu/best_way_to_import_parquet_files_into_multiple/', 'over_18': False, 'edited': 1707876381.0, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.989+0000] {logging_mixin.py:188} INFO - {'id': '1aq07hq', 'title': 'Compiling a List of Essential Terms in Data Engineering', 'score': 2, 'num_comments': 3, 'author': Redditor(name='Data-Queen-Mayra'), 'created_utc': 1707847929.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq07hq/compiling_a_list_of_essential_terms_in_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.991+0000] {logging_mixin.py:188} INFO - {'id': '1aqmlce', 'title': 'Dataform works in Mac but not Windows', 'score': 1, 'num_comments': 0, 'author': Redditor(name='anfawave'), 'created_utc': 1707916426.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqmlce/dataform_works_in_mac_but_not_windows/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.992+0000] {logging_mixin.py:188} INFO - {'id': '1aqm2qq', 'title': 'Challenges of Multiple Data Products, Duplication Management, and Governance', 'score': 1, 'num_comments': 0, 'author': Redditor(name='growth_man'), 'created_utc': 1707914812.0, 'url': 'https://moderndata101.substack.com/p/managing-the-evolving-landscape-of-data-products', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.994+0000] {logging_mixin.py:188} INFO - {'id': '1aqlxsa', 'title': 'Why BigQuery exports are to a single table?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='aruntdharan'), 'created_utc': 1707914373.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqlxsa/why_bigquery_exports_are_to_a_single_table/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.995+0000] {logging_mixin.py:188} INFO - {'id': '1aqizct', 'title': 'From Data scientist/analyst to Data engineer', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Larry_Jr64'), 'created_utc': 1707903052.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqizct/from_data_scientistanalyst_to_data_engineer/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:53.998+0000] {logging_mixin.py:188} INFO - {'id': '1aqi1f4', 'title': 'How to implement results from Spark profiling to actual data quality checks (on Sodacore preferably)', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Islamic_justice'), 'created_utc': 1707898880.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqi1f4/how_to_implement_results_from_spark_profiling_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.005+0000] {logging_mixin.py:188} INFO - {'id': '1aqft3w', 'title': 'How large is the market of text data entry classification/annotation? And how do data entry outsourcing companies work?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Ooker777'), 'created_utc': 1707890150.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqft3w/how_large_is_the_market_of_text_data_entry/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.013+0000] {logging_mixin.py:188} INFO - {'id': '1aqbjlu', 'title': 'Seeking Advice on Architecting a Data Project for Patent Analysis for an academic project', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Positive_Temporary77'), 'created_utc': 1707876674.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aqbjlu/seeking_advice_on_architecting_a_data_project_for/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.021+0000] {logging_mixin.py:188} INFO - {'id': '1aq9o0f', 'title': 'Data Analytics Platform Challenges and Interim Solutions: Seeking Advice', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Crow2525'), 'created_utc': 1707871285.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq9o0f/data_analytics_platform_challenges_and_interim/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.030+0000] {logging_mixin.py:188} INFO - {'id': '1aq76lv', 'title': 'VectorBT for Quantitative Analysis in Python', 'score': 0, 'num_comments': 0, 'author': Redditor(name='fancypigollo'), 'created_utc': 1707864873.0, 'url': 'https://youtu.be/t93aVVAP19E?si=PjXIOOinxDI-KzxU', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.032+0000] {logging_mixin.py:188} INFO - {'id': '1apy1bd', 'title': 'Free Badges.', 'score': 0, 'num_comments': 1, 'author': Redditor(name='Wide_Philosopher9589'), 'created_utc': 1707842785.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apy1bd/free_badges/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.036+0000] {logging_mixin.py:188} INFO - {'id': '1aqfxq5', 'title': '15 Best FREE SQL Courses and Certifications Online in 2024', 'score': 0, 'num_comments': 0, 'author': Redditor(name='Aqsa81'), 'created_utc': 1707890581.0, 'url': 'https://www.mltut.com/best-free-sql-courses/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-14T15:17:54.307+0000] {python.py:201} INFO - Done. Returned value was: /opt/airflow/data/output/reddit_20240214.csv
[2024-02-14T15:17:54.452+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20240213T000000, start_date=20240214T151750, end_date=20240214T151754
[2024-02-14T15:17:54.628+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-14T15:17:54.719+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
