[2024-02-13T22:03:12.230+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-13T22:03:09.270425+00:00 [queued]>
[2024-02-13T22:03:12.248+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-13T22:03:09.270425+00:00 [queued]>
[2024-02-13T22:03:12.249+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-13T22:03:12.276+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-02-13 22:03:09.270425+00:00
[2024-02-13T22:03:12.285+0000] {standard_task_runner.py:60} INFO - Started process 81 to run task
[2024-02-13T22:03:12.292+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-02-13T22:03:09.270425+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpd_4cy5c1']
[2024-02-13T22:03:12.297+0000] {standard_task_runner.py:88} INFO - Job 29: Subtask reddit_extraction
[2024-02-13T22:03:12.394+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-13T22:03:09.270425+00:00 [running]> on host edfa37962e49
[2024-02-13T22:03:12.545+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ahmed Elsharkawy' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-02-13T22:03:09.270425+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-02-13T22:03:09.270425+00:00'
[2024-02-13T22:03:12.551+0000] {logging_mixin.py:188} INFO - connected to reddit!
[2024-02-13T22:03:14.144+0000] {logging_mixin.py:188} INFO - {'id': '1aphlml', 'title': 'Using pandas in a data-intensive application - what the best, RAM-efficient, alternative?', 'score': 38, 'num_comments': 32, 'author': Redditor(name='NFeruch'), 'created_utc': 1707789155.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aphlml/using_pandas_in_a_dataintensive_application_what/', 'over_18': False, 'edited': 1707789616.0, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.146+0000] {logging_mixin.py:188} INFO - {'id': '1apolbz', 'title': 'The only two books you need to read about CI/CD and Data', 'score': 35, 'num_comments': 22, 'author': Redditor(name='OnlyFish7104'), 'created_utc': 1707812439.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apolbz/the_only_two_books_you_need_to_read_about_cicd/', 'over_18': False, 'edited': 1707812720.0, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.147+0000] {logging_mixin.py:188} INFO - {'id': '1apkimj', 'title': "What are instances where data storage, ETL, analytics, etc don't make sense on the cloud?", 'score': 26, 'num_comments': 20, 'author': Redditor(name='Reddit_Account_C-137'), 'created_utc': 1707797667.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apkimj/what_are_instances_where_data_storage_etl/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.147+0000] {logging_mixin.py:188} INFO - {'id': '1apqjnd', 'title': 'Pick 30% paybump for a small company or work in a big bank?', 'score': 24, 'num_comments': 26, 'author': Redditor(name='Leopatto'), 'created_utc': 1707820828.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apqjnd/pick_30_paybump_for_a_small_company_or_work_in_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.148+0000] {logging_mixin.py:188} INFO - {'id': '1apkw7y', 'title': 'Resources for data modeling and building a data architecture for event data', 'score': 19, 'num_comments': 16, 'author': Redditor(name='Several_Percentage_5'), 'created_utc': 1707798861.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apkw7y/resources_for_data_modeling_and_building_a_data/', 'over_18': False, 'edited': 1707822875.0, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.149+0000] {logging_mixin.py:188} INFO - {'id': '1apz616', 'title': 'Passed AWS Data Engineer - Associate !', 'score': 18, 'num_comments': 9, 'author': Redditor(name='dev_lvl80'), 'created_utc': 1707845473.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apz616/passed_aws_data_engineer_associate/', 'over_18': False, 'edited': 1707847512.0, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.150+0000] {logging_mixin.py:188} INFO - {'id': '1apdkil', 'title': 'How to properly structure and partition an S3 bucket for raw data storage from several sources?', 'score': 9, 'num_comments': 5, 'author': Redditor(name='NotGuiltySparkk'), 'created_utc': 1707778238.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apdkil/how_to_properly_structure_and_partition_an_s3/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.151+0000] {logging_mixin.py:188} INFO - {'id': '1apzymj', 'title': 'How would I go about creating a small-scale data warehouse for a small business team?', 'score': 11, 'num_comments': 11, 'author': Redditor(name='AstralSerenity'), 'created_utc': 1707847340.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apzymj/how_would_i_go_about_creating_a_smallscale_data/', 'over_18': False, 'edited': 1707847774.0, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.152+0000] {logging_mixin.py:188} INFO - {'id': '1apwl21', 'title': 'Dagster Feedback?', 'score': 8, 'num_comments': 10, 'author': Redditor(name='minormisgnomer'), 'created_utc': 1707839274.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apwl21/dagster_feedback/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.153+0000] {logging_mixin.py:188} INFO - {'id': '1apip8g', 'title': 'Whats the proper way to apply for internal job', 'score': 8, 'num_comments': 10, 'author': Redditor(name='liskeeksil'), 'created_utc': 1707792313.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apip8g/whats_the_proper_way_to_apply_for_internal_job/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.154+0000] {logging_mixin.py:188} INFO - {'id': '1apv4t0', 'title': 'Connectomics Data Challenge', 'score': 7, 'num_comments': 0, 'author': Redditor(name='amyleerobinson'), 'created_utc': 1707835553.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv4t0/connectomics_data_challenge/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.155+0000] {logging_mixin.py:188} INFO - {'id': '1aq0u4f', 'title': 'Job Market for Foreigners', 'score': 3, 'num_comments': 9, 'author': Redditor(name='luishacm'), 'created_utc': 1707849432.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq0u4f/job_market_for_foreigners/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.156+0000] {logging_mixin.py:188} INFO - {'id': '1appuju', 'title': 'Are GenAI& PandasAi safe to use for confidential data ??', 'score': 5, 'num_comments': 5, 'author': Redditor(name='TylerTheBat'), 'created_utc': 1707817934.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appuju/are_genai_pandasai_safe_to_use_for_confidential/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.157+0000] {logging_mixin.py:188} INFO - {'id': '1aq01f4', 'title': 'one-to-one relationships in star schema', 'score': 5, 'num_comments': 5, 'author': Redditor(name='pdxtechnologist'), 'created_utc': 1707847529.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq01f4/onetoone_relationships_in_star_schema/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.158+0000] {logging_mixin.py:188} INFO - {'id': '1apktdn', 'title': 'Can we use ADF to copy data from Salesforce to Snowflake directly without staging data in Blob storage?', 'score': 4, 'num_comments': 7, 'author': Redditor(name='JK_1975'), 'created_utc': 1707798612.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apktdn/can_we_use_adf_to_copy_data_from_salesforce_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.159+0000] {logging_mixin.py:188} INFO - {'id': '1apxt0o', 'title': 'Data teams building in public repositories', 'score': 3, 'num_comments': 0, 'author': Redditor(name='Wingsofpeace7'), 'created_utc': 1707842230.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apxt0o/data_teams_building_in_public_repositories/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.160+0000] {logging_mixin.py:188} INFO - {'id': '1aptdwv', 'title': 'Teradata Vantageâ„¢ destination now available on Airbyte Cloud', 'score': 3, 'num_comments': 0, 'author': Redditor(name='JanethL'), 'created_utc': 1707830668.0, 'url': 'https://medium.com/teradata/teradata-vantage-destination-now-available-on-airbyte-cloud-1eed7479e40e', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.161+0000] {logging_mixin.py:188} INFO - {'id': '1aps1ts', 'title': 'Using Power BI as frontend and Databricks as compute engine for data products', 'score': 3, 'num_comments': 4, 'author': Redditor(name='No_Lawfulness_6252'), 'created_utc': 1707826507.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aps1ts/using_power_bi_as_frontend_and_databricks_as/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.162+0000] {logging_mixin.py:188} INFO - {'id': '1appi2g', 'title': 'Partitioning Limit in Kafka', 'score': 3, 'num_comments': 2, 'author': Redditor(name='Plus-Author9252'), 'created_utc': 1707816417.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appi2g/partitioning_limit_in_kafka/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.162+0000] {logging_mixin.py:188} INFO - {'id': '1apv2d7', 'title': 'How to establish an OLE DB Destination in SSIS?', 'score': 2, 'num_comments': 0, 'author': Redditor(name='imperialka'), 'created_utc': 1707835372.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv2d7/how_to_establish_an_ole_db_destination_in_ssis/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.163+0000] {logging_mixin.py:188} INFO - {'id': '1apslj8', 'title': '9 Ways to Sell Data Services to Non-Data-Savvy Clients', 'score': 2, 'num_comments': 0, 'author': Redditor(name='sbalnojan'), 'created_utc': 1707828296.0, 'url': 'https://arch.dev/blog/9-ways-to-sell-data-services-to-non-data-savvy-clients/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.164+0000] {logging_mixin.py:188} INFO - {'id': '1aps4cd', 'title': 'Vertex ai and code', 'score': 2, 'num_comments': 0, 'author': Redditor(name='Total_Definition_401'), 'created_utc': 1707826748.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aps4cd/vertex_ai_and_code/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.165+0000] {logging_mixin.py:188} INFO - {'id': '1aposzs', 'title': 'Distributed time-series processing?', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Sea_Pipe9828'), 'created_utc': 1707813349.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aposzs/distributed_timeseries_processing/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.166+0000] {logging_mixin.py:188} INFO - {'id': '1apl1l7', 'title': 'Do you use a service mesh, manage IPs yourself?', 'score': 1, 'num_comments': 1, 'author': Redditor(name='DuckDatum'), 'created_utc': 1707799331.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apl1l7/do_you_use_a_service_mesh_manage_ips_yourself/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.167+0000] {logging_mixin.py:188} INFO - {'id': '1aphgks', 'title': 'Data quality tool for extracts (txt/delimited, .csv etcâ€¦)', 'score': 2, 'num_comments': 2, 'author': Redditor(name='mg_1987'), 'created_utc': 1707788747.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aphgks/data_quality_tool_for_extracts_txtdelimited_csv/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.168+0000] {logging_mixin.py:188} INFO - {'id': '1aq0dor', 'title': 'How to open files from Databricks Workspace in Notebooks?', 'score': 1, 'num_comments': 4, 'author': Redditor(name='Mysterious_Two_810'), 'created_utc': 1707848329.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq0dor/how_to_open_files_from_databricks_workspace_in/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.169+0000] {logging_mixin.py:188} INFO - {'id': '1aq07hq', 'title': 'Compiling a List of Essential Terms in Data Engineering', 'score': 1, 'num_comments': 2, 'author': Redditor(name='Data-Queen-Mayra'), 'created_utc': 1707847929.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq07hq/compiling_a_list_of_essential_terms_in_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.170+0000] {logging_mixin.py:188} INFO - {'id': '1aq00v5', 'title': 'What is the difference between a data mart and a regular data model?', 'score': 2, 'num_comments': 1, 'author': Redditor(name='TaleLegal9085'), 'created_utc': 1707847492.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aq00v5/what_is_the_difference_between_a_data_mart_and_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.171+0000] {logging_mixin.py:188} INFO - {'id': '1apywog', 'title': 'What are you using to extract Google Analytics (GA4) and Google Ads data?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='giuliosmall'), 'created_utc': 1707844850.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apywog/what_are_you_using_to_extract_google_analytics/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.172+0000] {logging_mixin.py:188} INFO - {'id': '1apy1bd', 'title': 'Free Badges.', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Wide_Philosopher9589'), 'created_utc': 1707842785.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apy1bd/free_badges/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.173+0000] {logging_mixin.py:188} INFO - {'id': '1apv42h', 'title': 'Using dbt with two different snowflake accounts? Looking for input.', 'score': 1, 'num_comments': 4, 'author': Redditor(name='MasterKluch'), 'created_utc': 1707835500.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apv42h/using_dbt_with_two_different_snowflake_accounts/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.174+0000] {logging_mixin.py:188} INFO - {'id': '1aptwme', 'title': 'folks in mid-sized startups, need help in validating my idea ðŸ™Œ', 'score': 1, 'num_comments': 0, 'author': Redditor(name='thehungryindian'), 'created_utc': 1707832153.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aptwme/folks_in_midsized_startups_need_help_in/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.175+0000] {logging_mixin.py:188} INFO - {'id': '1aptmob', 'title': 'My ETL performs full load every day but I want to extract true I/U/Ds out of it.', 'score': 1, 'num_comments': 0, 'author': Redditor(name='gkmanu9'), 'created_utc': 1707831389.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aptmob/my_etl_performs_full_load_every_day_but_i_want_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.176+0000] {logging_mixin.py:188} INFO - {'id': '1apry9n', 'title': 'CosmosDb (mongo) to Postgres', 'score': 1, 'num_comments': 1, 'author': Redditor(name='quincycs'), 'created_utc': 1707826156.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apry9n/cosmosdb_mongo_to_***/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.177+0000] {logging_mixin.py:188} INFO - {'id': '1apqda9', 'title': 'Why not send processed data from speed layer to batch layer in Lambda?', 'score': 1, 'num_comments': 3, 'author': Redditor(name='No_Dentist7884'), 'created_utc': 1707820110.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apqda9/why_not_send_processed_data_from_speed_layer_to/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.178+0000] {logging_mixin.py:188} INFO - {'id': '1apq39i', 'title': 'Best Practices for Updating Raw Data in Data Science Projects?', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Free-Orange2290'), 'created_utc': 1707818971.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apq39i/best_practices_for_updating_raw_data_in_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.179+0000] {logging_mixin.py:188} INFO - {'id': '1appyni', 'title': 'Data Collection / Asyncio / Brightdata Proxies', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Saa3dLfachil'), 'created_utc': 1707818442.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1appyni/data_collection_asyncio_brightdata_proxies/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.180+0000] {logging_mixin.py:188} INFO - {'id': '1apks31', 'title': 'Who are using data virtualization tools and whatâ€™s the best so far?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='ZetarisCommunityLead'), 'created_utc': 1707798497.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apks31/who_are_using_data_virtualization_tools_and_whats/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.181+0000] {logging_mixin.py:188} INFO - {'id': '1apc9bk', 'title': 'Typical Integrations and Tools used in Health Tech', 'score': 0, 'num_comments': 3, 'author': Redditor(name='Patient_Amount3039'), 'created_utc': 1707774982.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1apc9bk/typical_integrations_and_tools_used_in_health_tech/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-13T22:03:14.214+0000] {python.py:201} INFO - Done. Returned value was: /opt/airflow/data/output/reddit_20240213.csv
[2024-02-13T22:03:14.257+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20240213T220309, start_date=20240213T220312, end_date=20240213T220314
[2024-02-13T22:03:14.316+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-13T22:03:14.356+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
