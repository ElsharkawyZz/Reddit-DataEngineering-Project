[2024-02-12T18:56:33.888+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-12T18:56:30.002656+00:00 [queued]>
[2024-02-12T18:56:33.910+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-12T18:56:30.002656+00:00 [queued]>
[2024-02-12T18:56:33.911+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-02-12T18:56:33.949+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-02-12 18:56:30.002656+00:00
[2024-02-12T18:56:33.961+0000] {standard_task_runner.py:60} INFO - Started process 80 to run task
[2024-02-12T18:56:33.969+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-02-12T18:56:30.002656+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpvzkvgrh0']
[2024-02-12T18:56:33.975+0000] {standard_task_runner.py:88} INFO - Job 14: Subtask reddit_extraction
[2024-02-12T18:56:34.117+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-02-12T18:56:30.002656+00:00 [running]> on host 9c5f8f1aa41b
[2024-02-12T18:56:34.330+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ahmed Elsharkawy' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-02-12T18:56:30.002656+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-02-12T18:56:30.002656+00:00'
[2024-02-12T18:56:34.337+0000] {logging_mixin.py:188} INFO - connected to reddit!
[2024-02-12T18:56:35.729+0000] {logging_mixin.py:188} INFO - {'id': '1aofpbr', 'title': 'What we learned after running Airflow on Kubernetes for 2 years', 'score': 158, 'num_comments': 14, 'author': Redditor(name='UpvoteBeast'), 'created_utc': 1707678469.0, 'url': 'https://api.daily.dev/r/HAWJyvDVy', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.730+0000] {logging_mixin.py:188} INFO - {'id': '1aofkv9', 'title': '[Updated] Personal End-End ETL data pipeline(GCP, SPARK, AIRFLOW, TERRAFORM, DOCKER, DL, D3.JS)', 'score': 58, 'num_comments': 14, 'author': Redditor(name='AffectionateEmu8146'), 'created_utc': 1707678149.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aofkv9/updated_personal_endend_etl_data_pipelinegcp/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.731+0000] {logging_mixin.py:188} INFO - {'id': '1aopq7t', 'title': 'Pandas, high coupling and single responsibility principle in data pipelines', 'score': 35, 'num_comments': 15, 'author': Redditor(name='Confident_Watch8207'), 'created_utc': 1707706242.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aopq7t/pandas_high_coupling_and_single_responsibility/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.732+0000] {logging_mixin.py:188} INFO - {'id': '1aonpuf', 'title': 'Isnâ€™t DBT an unecessary layer if you use BigQuery ?', 'score': 29, 'num_comments': 63, 'author': Redditor(name='VegetableFan6622'), 'created_utc': 1707699762.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aonpuf/isnt_dbt_an_unecessary_layer_if_you_use_bigquery/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.733+0000] {logging_mixin.py:188} INFO - {'id': '1aos0o3', 'title': 'How do I write a data pipeline (ETL) ?', 'score': 14, 'num_comments': 3, 'author': Redditor(name='c0m94d3'), 'created_utc': 1707713997.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aos0o3/how_do_i_write_a_data_pipeline_etl/', 'over_18': False, 'edited': 1707742199.0, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.734+0000] {logging_mixin.py:188} INFO - {'id': '1ap40zg', 'title': 'Data Engineering vs Data Engineering', 'score': 16, 'num_comments': 9, 'author': Redditor(name='apple_pie_52'), 'created_utc': 1707755384.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap40zg/data_engineering_vs_data_engineering/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.735+0000] {logging_mixin.py:188} INFO - {'id': '1ap2xop', 'title': 'Thoughts on OneTable/XTable?', 'score': 11, 'num_comments': 4, 'author': Redditor(name='Data_cruncher'), 'created_utc': 1707752677.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap2xop/thoughts_on_onetablextable/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.736+0000] {logging_mixin.py:188} INFO - {'id': '1aopf7d', 'title': 'What technology would you use if you had a txt extract of a customer data with 16 million rows, and 30 columns and had to make a "user friendly" filtering system?', 'score': 11, 'num_comments': 15, 'author': Redditor(name='Candid94'), 'created_utc': 1707705251.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aopf7d/what_technology_would_you_use_if_you_had_a_txt/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.737+0000] {logging_mixin.py:188} INFO - {'id': '1aol2vr', 'title': 'GenAI and DE', 'score': 7, 'num_comments': 5, 'author': Redditor(name='Wise_Shop6419'), 'created_utc': 1707692116.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aol2vr/genai_and_de/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.738+0000] {logging_mixin.py:188} INFO - {'id': '1ap269w', 'title': 'Advice for someone trying to transition into data engineering from academia?', 'score': 7, 'num_comments': 8, 'author': Redditor(name='ianmgull'), 'created_utc': 1707750659.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap269w/advice_for_someone_trying_to_transition_into_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.739+0000] {logging_mixin.py:188} INFO - {'id': '1aoygvj', 'title': 'Best approach to 3rd ingest data into Redshift / Snowflake?', 'score': 7, 'num_comments': 3, 'author': Redditor(name='Peivol'), 'created_utc': 1707739412.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoygvj/best_approach_to_3rd_ingest_data_into_redshift/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.740+0000] {logging_mixin.py:188} INFO - {'id': '1aoenig', 'title': 'Dataverse', 'score': 5, 'num_comments': 17, 'author': Redditor(name='Ancient-Entry-6436'), 'created_utc': 1707675829.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoenig/dataverse/', 'over_18': False, 'edited': 1707699634.0, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.741+0000] {logging_mixin.py:188} INFO - {'id': '1aovhqs', 'title': 'Is dbt still relevant on Snowflake with Dynamic Tables?', 'score': 6, 'num_comments': 3, 'author': Redditor(name='nydasco'), 'created_utc': 1707727196.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aovhqs/is_dbt_still_relevant_on_snowflake_with_dynamic/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.742+0000] {logging_mixin.py:188} INFO - {'id': '1ap3flw', 'title': 'Managing SQL Table Changes', 'score': 4, 'num_comments': 2, 'author': Redditor(name='machinegunke11y'), 'created_utc': 1707753939.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap3flw/managing_sql_table_changes/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.743+0000] {logging_mixin.py:188} INFO - {'id': '1aoz9ic', 'title': 'How did you choose your BI setup?', 'score': 5, 'num_comments': 6, 'author': Redditor(name='AdImaginary8024'), 'created_utc': 1707742134.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoz9ic/how_did_you_choose_your_bi_setup/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.744+0000] {logging_mixin.py:188} INFO - {'id': '1aoy4oo', 'title': 'I developed a cool new LLM agent that helps with investigating and resolving alerts faster', 'score': 4, 'num_comments': 1, 'author': Redditor(name='Old_Cauliflower6316'), 'created_utc': 1707738198.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoy4oo/i_developed_a_cool_new_llm_agent_that_helps_with/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.745+0000] {logging_mixin.py:188} INFO - {'id': '1aoue6j', 'title': 'How to manage Hot and Cold Tables for Streaming Data', 'score': 2, 'num_comments': 1, 'author': Redditor(name='HousingStriking3770'), 'created_utc': 1707722542.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoue6j/how_to_manage_hot_and_cold_tables_for_streaming/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.746+0000] {logging_mixin.py:188} INFO - {'id': '1ap22x7', 'title': 'Study advise for DP-203 Aspirants.', 'score': 5, 'num_comments': 1, 'author': Redditor(name='Vikinghehe'), 'created_utc': 1707750407.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap22x7/study_advise_for_dp203_aspirants/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.747+0000] {logging_mixin.py:188} INFO - {'id': '1aouc2b', 'title': 'Viable starting paths to DE?', 'score': 3, 'num_comments': 1, 'author': Redditor(name='Kylerhanley'), 'created_utc': 1707722313.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aouc2b/viable_starting_paths_to_de/', 'over_18': False, 'edited': 1707722769.0, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.748+0000] {logging_mixin.py:188} INFO - {'id': '1aohyqj', 'title': 'Nsx VMware', 'score': 3, 'num_comments': 0, 'author': Redditor(name='OldParticular2326'), 'created_utc': 1707684144.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aohyqj/nsx_vmware/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.749+0000] {logging_mixin.py:188} INFO - {'id': '1ap0ygf', 'title': 'dlt (Data Load Tool) adds Databricks and Azure Synapse destinations', 'score': 3, 'num_comments': 0, 'author': Redditor(name='Thinker_Assignment'), 'created_utc': 1707747301.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap0ygf/dlt_data_load_tool_adds_databricks_and_azure/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.750+0000] {logging_mixin.py:188} INFO - {'id': '1aoy0ku', 'title': 'Loading big query data to spark dataframe.', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Dr_Fida'), 'created_utc': 1707737768.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoy0ku/loading_big_query_data_to_spark_dataframe/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.750+0000] {logging_mixin.py:188} INFO - {'id': '1aogoyd', 'title': 'A Kafka Connect Single Message Transform (SMT) that enables you to append the record key to the value as a named field', 'score': 2, 'num_comments': 0, 'author': Redditor(name='eladleev'), 'created_utc': 1707680980.0, 'url': 'https://github.com/EladLeev/KeyToField-smt', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.751+0000] {logging_mixin.py:188} INFO - {'id': '1aogc7m', 'title': 'Data API', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Hot_Map_7868'), 'created_utc': 1707680103.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aogc7m/data_api/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.752+0000] {logging_mixin.py:188} INFO - {'id': '1ap5xup', 'title': 'Securing Patient Data in Pharma/Healthcare.', 'score': 2, 'num_comments': 2, 'author': Redditor(name='throwaway_112801'), 'created_utc': 1707759979.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap5xup/securing_patient_data_in_pharmahealthcare/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.753+0000] {logging_mixin.py:188} INFO - {'id': '1ap58sg', 'title': 'Rethinking Serverless: The Price of Convenience', 'score': 1, 'num_comments': 0, 'author': Redditor(name='sync_jeff'), 'created_utc': 1707758293.0, 'url': 'https://medium.com/sync-computing/rethinking-serverless-the-price-of-convenience-9b9e29549d3b', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.754+0000] {logging_mixin.py:188} INFO - {'id': '1ap55q1', 'title': 'There is a way to block a catalog access on databricks if connected to powerbi/tableau?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='raffapaiva'), 'created_utc': 1707758092.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap55q1/there_is_a_way_to_block_a_catalog_access_on/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.755+0000] {logging_mixin.py:188} INFO - {'id': '1ap379e', 'title': 'Call snowpark stored procedures from power automate', 'score': 1, 'num_comments': 0, 'author': Redditor(name='asud_w_asud'), 'created_utc': 1707753361.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap379e/call_snowpark_stored_procedures_from_power/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.756+0000] {logging_mixin.py:188} INFO - {'id': '1aoxq13', 'title': 'SAP HANA jobs', 'score': 1, 'num_comments': 3, 'author': Redditor(name='Adorable_Finance3027'), 'created_utc': 1707736655.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoxq13/sap_hana_jobs/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.758+0000] {logging_mixin.py:188} INFO - {'id': '1aowiur', 'title': 'The dbt Materialzed_views Materialization', 'score': 1, 'num_comments': 0, 'author': Redditor(name='etsh_96'), 'created_utc': 1707731795.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aowiur/the_dbt_materialzed_views_materialization/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.759+0000] {logging_mixin.py:188} INFO - {'id': '1aolwjt', 'title': 'ORM vs query builder', 'score': 1, 'num_comments': 2, 'author': Redditor(name='colet_te'), 'created_utc': 1707694360.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aolwjt/orm_vs_query_builder/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.760+0000] {logging_mixin.py:188} INFO - {'id': '1aolkgc', 'title': 'Experience with Abbott?', 'score': 1, 'num_comments': 4, 'author': Redditor(name='Terrible_Mud5318'), 'created_utc': 1707693429.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aolkgc/experience_with_abbott/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.761+0000] {logging_mixin.py:188} INFO - {'id': '1ap64p9', 'title': 'Freshers into Data Engineering, Is hiriing going on or not', 'score': 0, 'num_comments': 3, 'author': Redditor(name='ganwaniKamal'), 'created_utc': 1707760439.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap64p9/freshers_into_data_engineering_is_hiriing_going/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.762+0000] {logging_mixin.py:188} INFO - {'id': '1ap2asm', 'title': 'snowflake - tracking changes', 'score': 0, 'num_comments': 0, 'author': Redditor(name='87keicam'), 'created_utc': 1707750992.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ap2asm/snowflake_tracking_changes/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.763+0000] {logging_mixin.py:188} INFO - {'id': '1aoj4m3', 'title': 'Complex data transformations in azure', 'score': 0, 'num_comments': 6, 'author': Redditor(name='lschozar'), 'created_utc': 1707687098.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1aoj4m3/complex_data_transformations_in_azure/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-02-12T18:56:35.798+0000] {python.py:201} INFO - Done. Returned value was: None
[2024-02-12T18:56:35.815+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20240212T185630, start_date=20240212T185633, end_date=20240212T185635
[2024-02-12T18:56:35.878+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-12T18:56:35.910+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
